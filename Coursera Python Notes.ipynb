{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heading 1\n",
    "## Heading 2\n",
    "### Heading 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Heading |  |Heading 2|\n",
    "|---------|  |---------|\n",
    "|cell|       |cell2|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Column 1||Column 2||Column 3|\n",
    "|--------||--------||--------|\n",
    "|11|      |12|      |13|\n",
    "|21|      |22|      |23|\n",
    "|31|      |32|      |33|\n",
    "|41|      |42|      |43|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preamble imports all the needed libraries needed to perform the desired operations. For explaratory data analysis inpython these are the most common libraries but we can import any needed libraries.\n",
    "\n",
    "##### pandas\n",
    "For data manipulation i.e. structuring data and performing numerical operations. Aliased using pd to make calling functions easier. for example pd.reacd_csv() instead of pandas.read_csv. Aliases are defined by user, most commonly, pandas is aliased as pd this. \n",
    "\n",
    "##### Numpy \n",
    "used for handling high-level mathematical operations in large arrays in matrices i.e. performing mathematical operations on very large data sets. Aliased using np\n",
    "\n",
    "##### Seaborn\n",
    "is based on matplotlib but created more visually appealing statistical data visualizations. aliased usinf sns\n",
    "\n",
    "##### Matplotlib\n",
    "this is a python library to create data visualizations. in the preamble below we see matplotlib.pyplot this calls one specific function from the matplotlib library. aliased using plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns                       #visualisation\n",
    "import matplotlib.pyplot as plt             #visualisation\n",
    "%matplotlib inline     \n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below shows you hwo to get to know your data. looking at the first five rows to see what your data looks like and the last five rows to see how many rows and what the end of your data looks like, You can also look at the data types. the shape function allows you to see the number of rows and columns in your data fram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # to read csv into a data frame. datafram is named df and defined as pd.read_csv. this is a pandas function so we have to use pd.\n",
    "df = pd.read_csv(\"data.csv\") function \n",
    "\n",
    "\n",
    "#As defined above, df refers to the csv we read into a data frame so we have to write df. to specify which data frame we want the function to perform on\n",
    "\n",
    "df.head(5)  # To display the top 5 rows, \n",
    "    \n",
    "df.tail(5) # To display the botton 5 rows\n",
    "\n",
    "df.dtypes #Displays columns and data types\n",
    "\n",
    "df.shape # displays the number of rows and columns in your data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns in a Data frame\n",
    "\n",
    "You can drop specific columns in your data frame by using the drop function this allows you to drop the columns you don't want. in the code below df is being redefined by dropping unwanted columns.\n",
    "\n",
    "Conversely, you can call the columns you do want by specifying the data frame name and columns within that data frame.\n",
    "\n",
    "You can also rename columns to keep data tables looking neat and concise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns in a data frame\n",
    "df = df.drop(['Engine Fuel Type', 'Market Category', 'Vehicle Style', 'Popularity', 'Number of Doors', 'Vehicle Size'], axis=1)\n",
    "df.head(5)\n",
    "\n",
    "# the code below specifies which columns you want to call in a specific dataframe.\n",
    "df(['Column Name 1','Column Name 2','Column Name 3'])\n",
    "\n",
    "# Renaming columns\n",
    "df = df.rename(columns={\"Engine HP\": \"HP\", \"Engine Cylinders\": \"Cylinders\", \"Transmission Type\": \"Transmission\", \"Driven_Wheels\": \"Drive Mode\",\"highway MPG\": \"MPG-H\", \"city mpg\": \"MPG-C\", \"MSRP\": \"Price\" })\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rows in a Data frame\n",
    "\n",
    "You can search for duplicate rows by using the duplicated function. specify the data frame you want to check then write the function duplicatd(). see the example below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the code below puts al the duplicate rows from the df data frame into a separate data frame called duplicate_rows_df\n",
    "duplicate_rows_df = df[df.duplicated()]\n",
    "\n",
    "# this code displays or prints the the text \"number of duplicate rows:\" followed by the duplicae_rows_df shape i.e. number of rows and columns\n",
    "print(\"number of duplicate rows: \", duplicate_rows_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()      # Used to count the number of rows\n",
    "\n",
    "df = df.drop_duplicates() # used to drop duplicate rows you can specify certain columns to drop duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Null Values\n",
    "\n",
    "To find null values specify the dataframe, write the isnull() function, and to count the number of null values wrtie the sum() function. isnull() identifies all null values, see the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code displays (prints) the number of all null values in the data frame df. \n",
    "print(df.isnull().sum())\n",
    "\n",
    "\n",
    "df = df.dropna()    # Dropping the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Outliers\n",
    "\n",
    "Using the Seaborn library we can calculate and plot outliers. this is only possible on columns that have a numerical value. \n",
    "First we creata box plot to see out data using the bocplot() function in the Seaborn library. we define the value to be plotted by x = df['Some Column'] see the example below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # creates a box plot for the price column. in the code we define X to be the price column in the data frame\n",
    "sns.boxplot(x=df['Price']) \n",
    "\n",
    "sns.boxplot(x=df['HP']) #box plot for horse power column\n",
    "\n",
    "sns.boxplot(x=df['Cylinders']) # box plot for cylinders column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to find the quartiles of each numerical column we use the function quantile() and specify quantile(.25) for the first quartile, quantile(.5) for the median, and quantile(.75) for the third quartile. to find th einter quartile range you then subtract quantile(.75) - qunatile(.25). in the code below we use variables to make things neater and more concise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers are considered values that are not within the lower bound and upper bound. The lowe bound is the first quartile - 1.5 *IQR and the upper bound is the third quartile + 1.5* IQR. to remove data points not in the LB and UB we use the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code redefines the data frame as all data points that are not less than the LB and are not greater than the UB\n",
    "df = df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots\n",
    "\n",
    "Below is code for a heatmap, histogram, and scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is for a histogram. The column we are counting frequencies on is the make of a car. we use df.make.value_counts\n",
    "# to specify that we want the make column and the frequency count. the .nlargest(40)orders the histogram from largest to \n",
    "# to smallest frquency.\n",
    "\n",
    "df.Make.value_counts().nlargest(40).plot(kind='bar', figsize=(10,5))\n",
    "plt.title(\"Number of cars by make\")\n",
    "plt.ylabel('Number of cars')\n",
    "plt.xlabel('Make');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the cod ebelow displays a heat map with a correlation table\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "# calculates correlation among numeric values\n",
    "c= df.corr()\n",
    "\n",
    "# uses the heatmap function, parameters used are c because we want to use the correlation value, cmpa is the colors we want to \n",
    "# use Br = Brown, B = Blue, G = Green.\n",
    "sns.heatmap(c,cmap=\"BrBG\",annot=True)\n",
    "\n",
    "# displays correlation in a tabular table\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code below is for a scatter plot\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.scatter(df['HP'], df['Price']) # identifies the two columns we want to test for correlation\n",
    "ax.set_xlabel('HP')        # x- axis label\n",
    "ax.set_ylabel('Price')     #y- axis label\n",
    "plt.show()          # displays scatter plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
